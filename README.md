# HACKATHON_LTD_-UniGoTo-

[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://unigoto.streamlit.app/)

<img src="https://github.com/Zagalskiy/ml_web_app/blob/main/Las_Teteras_Desesperadas.jpg" width="200" height="200" alt="Las Teteras Desesperadas">

# Документация к проекту на разработку рекомендательной системы
# для проекта UniGoTo. 

# 1. Введение

Цель проекта разработать ML-решение рекомендательной системы, способное сформировать персональные ранжированные списки направлений обучения в вузах для каждого уникального запроса на основе данных, вводимых пользователем рекомендательной системы.

Используются данные с информацией об интересах пользователя, включая фильмы, музыку, книги, игры, хобби и т. д. Данные представлены в виде отдельных страниц, массив в формате json из 999 значений. 

# 2. Архитектура рекомендательной системы:

- Парсинг данных с API, проверка столбцов, загрузка данных, формирование датасета.
- Фильтрация вспомогательных таблиц, очистка интересов от шумов, предобработка интересов.
- Модель рекомендации по интересам.

# 3. Описание рекомендательной системы:

## parser.py
## int_checker.py
## loader.py

## aux_filter.py
Описание: Этот скрипт выполняет очистку данных из файлов вспомогательных таблиц и сохраняет результаты в одноименные файлы. Он использует библиотеки pandas, os и zipfile.

Входные данные:
- "universities.csv", "faculties.csv", "countries.csv", "cities.csv" - файлы CSV с данными, требующими очистки.
- "data" - папка, содержащая файлы данных.

Выходные данные:
- "universities_filtered.csv", "faculties_filtered.csv", "countries_filtered.csv", "cities_filtered.csv" - файлы CSV с очищенными данными.

Шаги:
1. Получает путь к текущей папке скриптов.
2. Создается список имён файлов для загрузки.
3. Создается список имён столбцов для фильтрации.
4. Применяется по каждому файлу в списке.
5. Проверяется наличие ZIP-архива и загружается файл CSV в DataFrame.
6. Удаляются дубликаты.
7. Сортируются по возрастанию первых столбцов, фильтруем названия ВУЗов.
8. Сохраняет отфильтрованные данные в файлы universities_filtered.csv", "faculties_filtered.csv", "countries_filtered.csv", "cities_filtered.csv".

## pre_filter.py
Описание: Этот скрипт выполняет очистку данных из файла "combined_data.csv" и сохраняет результаты в файл "prefiltered_data.csv". Он использует библиотеки pandas, os и zipfile.

Входные данные:
- "combined_data.csv" - файл CSV с данными, требующими очистки.
- "data" - папка, содержащая файлы данных.

Выходные данные:
- "prefiltered_data.csv" - файл CSV с очищенными данными.

Шаги:
1. Проверяется наличие ZIP-архива "combined_data.zip". Если архив существует, его содержимое извлекается в папку "data".
2. Файл "combined_data.csv" загружается в объект DataFrame.
3. Создается список столбцов интересов пользователей и список столбцов с числовыми значениями.
4. Удаляются дубликаты и строки, в которых количество заполненных столбцов интересов меньше 3.
5. Создается список рекламных слов и фраз.
6. Создаем функцию проверки наличия рекламных слов в столбцах интересов и удаляем строки, содержащие рекламные слова в столбцах интересов.
7. Преобразуется типы данных столбцов 'country_id' и остальных столбцов с числовыми значениями в int16 и int32 соответственно.
8. Сохраняет отфильтрованные данные в файл "prefiltered_data.csv".


## noise_filter.py
Описание: Этот скрипт выполняет очистку данных из файла "prefiltered_data.csv" и сохраняет результаты в файл "filtered_data.csv". Он использует библиотеки pandas, re, os и zipfile.

Входные данные:
- "prefiltered_data.csv" - файл CSV с данными, требующими очистки.
- "data" - папка, содержащая файлы данных.

Выходные данные:
- "filtered_data.csv" - файл CSV с очищенными данными.

Шаги:
1. Проверяется наличие ZIP-архива "prefiltered_data.zip". Если архив существует, его содержимое извлекается в папку "data".
2. Файл "prefiltered_data.csv" загружается в объект DataFrame.
3. Создается список столбцов интересов пользователей.
4. Определяется функция "clean_text", которая применяется к столбцам интересов для очистки текста от лишних символов.
5. Заменяются пустые значения на "NaN", удаляются строки с "NaN" во всех 5 столбцах интересов.
6. Очищенные данные сохраняются в файл "filtered_data.csv".

## preprocessor.py
Описание: Этот скрипт выполняет предобработку данных из файла "filtered_data.csv" и сохраняет результаты в файл "preprocessed_data.csv". Он использует библиотеки pandas, re, os, zipfile, nltk, stopwords, wordnet и nltk.corpus.

Входные данные:
- "filtered_data.csv" - файл CSV с данными, требующими предобработки.
- "data" - папка, содержащая файлы данных.

Выходные данные:
- "preprocessed_data.csv" - файл CSV с предобработанными данными.

Шаги:
1. Проверяется наличие необходимых ресурсов NLTK перед их загрузкой.
2. Загружаются необходимые ресурсы для обработки текстовых данных из Natural Language Toolkit.
3. Проверяется наличие необходимых библиотек и ресурсов для работы скрипта.
4. Проверяется наличие ZIP-архива "filtered_data.zip". Если архив существует, его содержимое извлекается в папку "data".
5. Файл "filtered_data.csv" загружается в объект DataFrame.
6. Создается список столбцов интересов пользователей.
7. Определяется функция "preprocess_text", которая применяется к столбцам интересов для предобработки текста.
8. Определяется функция "clean_text", которая применяется к столбцам интересов для очистки текста от лишних символов.
9. Применяется функция "preprocess_text" к каждому набору интересов для каждой строки в DataFrame.
10. Применяется функция "clean_text" к каждому набору интересов для каждой строки в DataFrame.
11. Удаляются столбцы interest_col.
12. Сохраняются очищенные данные в файл "preprocessed_data.csv".

## recommendator.py
Скрипт выполняет обработку данных из сформированных ранее файлов и выводит рекомендацию ТОП-20 рекомендованных ВУЗов на основе предпочтений других пользователей из региона. Он использует библиотеки pandas, os, zipfile, scipy, sklearn. 

Входные данные:
- "universities_filtered.csv", "faculties_filtered.csv", "countries_filtered.csv", "cities_filtered.csv", "cities_regions.csv". Каждый из этих файлов содержит информацию об университетах, факультетах, странах, городах и регионах соответственно.
- данные вводимые пользователем

Выходные данные:
- ТОП-20 рекомендованных ВУЗов

Шаги:
1. Загрузка данных из файлов CSV в отдельные DataFrame universities_filtered.csv, faculties_filtered.csv, countries_filtered.csv, cities_filtered.csv, cities_regions.csv. 
2. Заполняются пропущенные значения в столбце 'preprocessed_interests'.
3. Создаются словари интересов пользователя.
4. Загружаем интересы пользователя, проверяем, обрабатывам и сохраняем в файл user_data.csv. 
5. Создание разреженной матрицы TF-IDF для преобразования строк интересов пользователей. Создается экземпляр TfidfVectorizer, который применяется к столбцу 'preprocessed_interests' DataFrame "data". Результатом является разреженная матрица TF-IDF, которая сохраняется в переменную tfidf_matrix.
6. Создание разреженной матрицы TF-IDF для интересов пользователя. Используется экземпляр TfidfVectorizer, который применяется к столбцу 'preprocessed_interests' DataFrame user_data. Результат сохраняется в переменную user_tfidf_matrix.
7. Вычисление косинусного сходства пользователя с другими пользователями. Результат сохраняется в переменную user_cosine_sim.
8. Получение ТОП-20 индексов пользователей с наибольшими косинусными сходствами. Результат сохраняется в переменную top_indices.
9. Создается функция вывода рекомендаций.
10. Вывод ТОП-20 ВУЗов на основе предпочтений пользователей с возможностью выбора города и региона. 

# 4. Применение рекомендательной системы

Рекомендательная система предназначена для анализа и поиска взаимосвязей между интересами пользователей уже поступивших или закончивших ВУЗы и пользователей абитуриентов. Данная система может предложить список ВУЗов в городе, регионе, стране.

# 5. Заключение

Рекомендательная система на данном этапе предусматривает только рекомендации ВУЗов в России. Главные перспективы  развития идеи это:
- расширение географии ВУЗов и подключение иностранных языков
- включение средних учебных заведений, школ, лицеев и т.д. 



